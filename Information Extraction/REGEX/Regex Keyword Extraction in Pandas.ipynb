{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/54440554/how-to-extract-a-keywordstring-from-a-column-in-pandas-dataframe-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Work\\Coding\\Data\\some-news.csv\")\n",
    "#Cleaning up garbage I injected with a previous process\n",
    "df = df.drop(\"Unnamed: 0\", axis=1)\n",
    "df = df.drop(\"Unnamed: 0.1\", axis=1)\n",
    "df['article'] = df['article'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "995"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article'] = df['article'].str.replace(\"&amp;\", \"&\") #Fix ampersand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The Indianapolis Colts made Andrew Luck the highest-paid player in NFL history this offseason with a five-year, $122-million contract with $89 million guaranteed. However, they're already finding that Luck's contract is inhibiting their ability to address weaknesses on other parts of the roster, particularly on defense. On Friday, Colts GM Ryan Grigson, who is under fire for the Colts 1-3 start, said that it's difficult to build up the team's defense with Luck making so much money. According to Keefer, Grigson did point out that the Colts still have young talent they're hoping to develop on defense. However, blaming Luck's contract — which the Colts gave him — for having a weak defense (30th in defensive DVOA) is not accurate. As others have pointed out, last year's Denver Broncos paid Peyton Manning $15 million in base salary while also boasting an elite defense. Luck also takes up $18.4 million against the salary cap this year, less than $1 million more than Manning did a year ago ($17.5 million). Much of this comes from drafting successfully, which the Colts have not done as well as elite teams like the Broncos or the Patriots, for instance. Now, with the Colts handcuffed to Luck's contract, drafting is going to become especially important, as will the use of whatever money they have in free agency. It's certainly possible to build a good defense with a high-paid quarterback, but if the Colts felt that paying Luck such a high sum of money would be difficult, perhaps they should have reconsidered what the final numbers. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe highest-paid player on all 32 NFL teams\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    \"\"\"\n",
    "    A simple function to clean up the data. All the words that\n",
    "    are not designated as a stop word is then lemmatized after\n",
    "    encoding and basic regex parsing are performed.\n",
    "    \"\"\"\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "    .encode('ascii', 'ignore')\n",
    "    .decode('utf-8', 'ignore')\n",
    "    .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = basic_clean(''.join(str(df['article'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(iconnit, indicates, expandable)             168\n",
       "(section, menu, sometimes)                   168\n",
       "(sometimes, previous, next)                  168\n",
       "(next, navigation, optionsnn)                168\n",
       "(expandable, section, menu)                  168\n",
       "(indicates, expandable, section)             168\n",
       "(previous, next, navigation)                 168\n",
       "(menu, sometimes, previous)                  168\n",
       "(president, donald, trump)                   107\n",
       "(nnnnchevron, iconnit, indicates)             84\n",
       "(optionsnn, nnnnchevron, iconnit)             84\n",
       "(navigation, optionsnn, nnnnchevron)          84\n",
       "(article, originally, appeared)               66\n",
       "(new, york, time)                             60\n",
       "(hyperallergic, nectar, ad)                   54\n",
       "(advertise, hyperallergic, nectar)            54\n",
       "(originally, appeared, recodenet)             53\n",
       "(new, york, city)                             42\n",
       "(u, president, donald)                        35\n",
       "(affordable, care, act)                       32\n",
       "(told, vice, news)                            29\n",
       "(nnnnnnnnchevron, iconnit, indicates)         18\n",
       "(president, barack, obama)                    18\n",
       "(washington, reuters, u)                      17\n",
       "(respond, request, comment)                   17\n",
       "(wall, street, journal)                       16\n",
       "(green, new, deal)                            15\n",
       "(united, state, china)                        15\n",
       "(donald, trump, said)                         15\n",
       "(polygenic, risk, score)                      14\n",
       "(george, w, bush)                             14\n",
       "(kim, jong, un)                               14\n",
       "(nnnnnnnnnnnnchevron, iconnit, indicates)     13\n",
       "(special, counsel, robert)                    13\n",
       "(south, china, sea)                           13\n",
       "(newsletter, get, best)                       12\n",
       "(attorney, general, jeff)                     12\n",
       "(president, barack, obamas)                   12\n",
       "(two, year, ago)                              12\n",
       "(sign, newsletter, get)                       12\n",
       "(reuters, u, president)                       12\n",
       "(world, war, ii)                              12\n",
       "(exit, poll, result)                          12\n",
       "(health, care, system)                        12\n",
       "(president, xi, jinping)                      11\n",
       "(somos, el, muro)                             11\n",
       "(president, united, state)                    11\n",
       "(law, enforcement, official)                  11\n",
       "(general, jeff, session)                      11\n",
       "(president, vladimir, putin)                  10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.Series(nltk.ngrams(words, 3)).value_counts())[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Apartment  = ['apartment', 'penthouse', 'duplex']\n",
    "House      = ['house', 'villa', 'country estate']\n",
    "Plot       = ['plot', 'land']\n",
    "Location   = ['New Delhi','Mumbai','Bangalore','Amritsar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = '|'.join(fr\"\\b{x}\\b\" for x in Location)\n",
    "# df['Location'] = df['Type'].str.extract(f'({pat})', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\bNew Delhi\\\\b|\\\\bMumbai\\\\b|\\\\bBangalore\\\\b|\\\\bAmritsar\\\\b'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Apartment' : Apartment,\n",
    "     'House' : House,\n",
    "     'Plot' : Plot}\n",
    "\n",
    "d1 = {k: oldk for oldk, oldv in d.items() for k in oldv}\n",
    "\n",
    "for k, v in d1.items():\n",
    "    df.loc[df['Type'].str.contains(k, case=False), 'Type'] = v"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPtests",
   "language": "python",
   "name": "nlptests"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
